{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYxbEBEr5pXDVubbGyDPl7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ROBEAZY/bdt-2024-17906342/blob/main/17906342_Tut4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 1\n",
        "import apache_beam as beam\n",
        "import csv\n",
        "import io\n",
        "\n",
        "# Define transformation class\n",
        "class Transform(beam.DoFn):\n",
        "    def process(self, element):\n",
        "        try:\n",
        "            # Parse the line using CSV reader to handle commas inside quotes correctly\n",
        "            reader = csv.reader(io.StringIO(element))\n",
        "            fields = next(reader)  # Read the first (and only) row of the CSV reader\n",
        "\n",
        "            # Ensure there are exactly 6 fields: user_id, name, gender, age, address, date_joined\n",
        "            if len(fields) != 6:\n",
        "                print(f\"Skipping malformed line (not exactly 6 fields): {element}\")\n",
        "                return\n",
        "\n",
        "            # Extract fields\n",
        "            user_id = fields[0].strip()\n",
        "            name = fields[1].strip()\n",
        "            gender = fields[2].strip().capitalize()  # Capitalize gender to \"Male\" or \"Female\"\n",
        "            age = fields[3].strip()\n",
        "\n",
        "            # Split address into city, state, and zip\n",
        "            address_parts = fields[4].strip().rsplit('-', 2)  # Split from the right to get last two parts as state and zip\n",
        "            if len(address_parts) == 3:\n",
        "                city = address_parts[0].strip()\n",
        "                state = address_parts[1].strip()\n",
        "                zip_code = address_parts[2].strip()\n",
        "                address = f\"{city},{state},{zip_code}\"  # Format as City, State, Zip\n",
        "            else:\n",
        "                address = fields[4].strip()  # Fall back to original address if split doesn't work\n",
        "\n",
        "            # Format the date to use hyphens instead of slashes\n",
        "            date_joined = fields[5].strip().replace('/', '-')\n",
        "\n",
        "            # Format the line as per the required output (semicolon-separated)\n",
        "            formatted_line = f\"{user_id};{name};{gender};{age}; {address};{date_joined}\"\n",
        "            yield formatted_line\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing line: {element}. Error: {e}\")\n",
        "\n",
        "# Custom print function for Beam\n",
        "def myprint(element):\n",
        "    print(element)\n",
        "\n",
        "# Define the pipeline\n",
        "with beam.Pipeline() as pipeline:\n",
        "    (\n",
        "        pipeline\n",
        "        | 'Read lines' >> beam.io.ReadFromText('/content/users_v.csv', skip_header_lines=1)  # Skip header\n",
        "        | 'Transform line' >> beam.ParDo(Transform())  # Apply transformations\n",
        "        | 'Sample 5 lines' >> beam.combiners.Sample.FixedSizeGlobally(5)  # print 5 lines\n",
        "        | 'Print 5 lines' >> beam.Map(lambda elements: [myprint(element) for element in elements])  # Print the elements\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sFp_n6sFCC2D",
        "outputId": "32199f91-0b8c-446e-c555-507df272ed53"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Missing pipeline option (runner). Executing pipeline using the default runner: DirectRunner.\n",
            "INFO:apache_beam.runners.worker.statecache:Creating state cache with size 104857600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1011;Colleen Vasquez;Female;62; Mirandaburgh,VT,52472;2013-02-15\n",
            "1804;David Douglas;Male;26; Camachoshire,CT,52129;2019-08-23\n",
            "1941;Patricia Harris;Female;58; Kennethmouth,HI,38828;2004-07-19\n",
            "1449;Joyce Robinson;Female;37; North Peter,NH,40020;2017-11-17\n",
            "41;Joshua Quinn;Male;62; Emilytown,NM,68576;2005-08-01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 2a\n",
        "import apache_beam as beam\n",
        "import csv\n",
        "import io\n",
        "\n",
        "# Define transformation class\n",
        "class Transform(beam.DoFn):\n",
        "    def process(self, element):\n",
        "        try:\n",
        "            # Parse the line using CSV reader to handle commas inside quotes correctly\n",
        "            reader = csv.reader(io.StringIO(element))\n",
        "            fields = next(reader)  # Read the first (and only) row of the CSV reader\n",
        "\n",
        "            # Ensure there are exactly 6 fields: user_id, name, gender, age, address, date_joined\n",
        "            if len(fields) != 6:\n",
        "                print(f\"Skipping malformed line (not exactly 6 fields): {element}\")\n",
        "                return\n",
        "\n",
        "            # Extract fields\n",
        "            user_id = fields[0].strip()\n",
        "            name = fields[1].strip()\n",
        "            gender = fields[2].strip().capitalize()  # Capitalize gender to \"Male\" or \"Female\"\n",
        "            age = fields[3].strip()\n",
        "\n",
        "            # Split address into city, state, and zip\n",
        "            address_parts = fields[4].strip().rsplit('-', 2)  # Split from the right to get last two parts as state and zip\n",
        "            if len(address_parts) == 3:\n",
        "                city = address_parts[0].strip()\n",
        "                state = address_parts[1].strip()\n",
        "                zip_code = address_parts[2].strip()\n",
        "                address = f\"{city},{state},{zip_code}\"  # Format as City, State, Zip\n",
        "            else:\n",
        "                address = fields[4].strip()  # Fall back to original address if split doesn't work\n",
        "\n",
        "            # Format the date to use hyphens instead of slashes\n",
        "            date_joined = fields[5].strip().replace('/', '-')\n",
        "\n",
        "            # Yield the gender as output\n",
        "            yield gender\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing line: {element}. Error: {e}\")\n",
        "\n",
        "# Define the pipeline\n",
        "with beam.Pipeline() as pipeline:\n",
        "    # Read lines and transform them to extract the gender\n",
        "    genders = (\n",
        "        pipeline\n",
        "        | 'Read lines' >> beam.io.ReadFromText('/content/users_v.csv', skip_header_lines=1)  # Skip header\n",
        "        | 'Extract gender' >> beam.ParDo(Transform())  # Extract the gender from each record\n",
        "    )\n",
        "\n",
        "    # Count the number of male and female customers\n",
        "    male_count = (\n",
        "        genders\n",
        "        | 'Filter males' >> beam.Filter(lambda gender: gender == 'Male')  # Filter male records\n",
        "        | 'Count males' >> beam.combiners.Count.Globally()  # Count the male records\n",
        "    )\n",
        "\n",
        "    female_count = (\n",
        "        genders\n",
        "        | 'Filter females' >> beam.Filter(lambda gender: gender == 'Female')  # Filter female records\n",
        "        | 'Count females' >> beam.combiners.Count.Globally()  # Count the female records\n",
        "    )\n",
        "\n",
        "    # Print the results\n",
        "    male_count | 'Print male count' >> beam.Map(lambda count: print(f\"Number of male customers: {count}\"))\n",
        "    female_count | 'Print female count' >> beam.Map(lambda count: print(f\"Number of female customers: {count}\"))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_s1b82xQJhK",
        "outputId": "b66d5d7c-afda-4781-f2e2-4b45f9714c88"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Missing pipeline option (runner). Executing pipeline using the default runner: DirectRunner.\n",
            "INFO:apache_beam.runners.worker.statecache:Creating state cache with size 104857600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of female customers: 1150\n",
            "Number of male customers: 1207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 2b\n",
        "import apache_beam as beam\n",
        "import csv\n",
        "import io\n",
        "\n",
        "# Define transformation class\n",
        "class ExtractDate(beam.DoFn):\n",
        "    def process(self, element):\n",
        "        try:\n",
        "            # Parse the line using CSV reader to handle commas inside quotes correctly\n",
        "            reader = csv.reader(io.StringIO(element))\n",
        "            fields = next(reader)  # Read the first (and only) row of the CSV reader\n",
        "\n",
        "            # Ensure there are exactly 6 fields: user_id, name, gender, age, address, date_joined\n",
        "            if len(fields) != 6:\n",
        "                print(f\"Skipping malformed line (not exactly 6 fields): {element}\")\n",
        "                return\n",
        "\n",
        "            # Extract the date_joined field and yield it\n",
        "            date_joined = fields[5].strip().replace('/', '-')  # Ensure date is formatted with hyphens\n",
        "            yield (date_joined, 1)  # Emit the date and count of 1 for each record\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing line: {element}. Error: {e}\")\n",
        "\n",
        "# Define the pipeline\n",
        "with beam.Pipeline() as pipeline:\n",
        "    # Read lines and extract the date_joined field with a count of 1 for each record\n",
        "    date_counts = (\n",
        "        pipeline\n",
        "        | 'Read lines' >> beam.io.ReadFromText('/content/users_v.csv', skip_header_lines=1)  # Skip header\n",
        "        | 'Extract date' >> beam.ParDo(ExtractDate())  # Extract date_joined and emit (date_joined, 1)\n",
        "        | 'Group by date' >> beam.CombinePerKey(sum)  # Sum the counts for each date\n",
        "    )\n",
        "\n",
        "    # Get the top 5 days by customer count\n",
        "    top_5_days = (\n",
        "        date_counts\n",
        "        | 'Top 5 days' >> beam.combiners.Top.Of(5, key=lambda x: x[1])  # Get top 5 based on customer count\n",
        "    )\n",
        "\n",
        "    # Print the top 5 results\n",
        "    top_5_days | 'Print top 5' >> beam.Map(lambda days: [print(f\"{day[0]}: {day[1]} customers\") for day in days])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9r28Wy39SWed",
        "outputId": "310740e5-fd7d-4e74-b82f-93ba7760fbaa"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Missing pipeline option (runner). Executing pipeline using the default runner: DirectRunner.\n",
            "INFO:apache_beam.runners.worker.statecache:Creating state cache with size 104857600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2018-10-17: 5 customers\n",
            "2011-05-13: 4 customers\n",
            "2001-10-11: 3 customers\n",
            "2015-05-16: 3 customers\n",
            "2015-01-26: 3 customers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 2c\n",
        "import apache_beam as beam\n",
        "import csv\n",
        "import io\n",
        "\n",
        "# Define transformation class\n",
        "class ExtractState(beam.DoFn):\n",
        "    def process(self, element):\n",
        "        try:\n",
        "            # Parse the line using CSV reader to handle commas inside quotes correctly\n",
        "            reader = csv.reader(io.StringIO(element))\n",
        "            fields = next(reader)  # Read the first (and only) row of the CSV reader\n",
        "\n",
        "            # Ensure there are exactly 6 fields: user_id, name, gender, age, address, date_joined\n",
        "            if len(fields) != 6:\n",
        "                print(f\"Skipping malformed line (not exactly 6 fields): {element}\")\n",
        "                return\n",
        "\n",
        "            # Extract the state from the address field (assumes address format: City-State-ZIP)\n",
        "            address_parts = fields[4].strip().rsplit('-', 2)  # Split from the right to get last two parts as state and zip\n",
        "            if len(address_parts) == 3:\n",
        "                state = address_parts[1].strip()  # State is the second-to-last part of the address\n",
        "                yield (state, 1)  # Emit the state and count of 1 for each record\n",
        "            else:\n",
        "                print(f\"Skipping malformed address: {fields[4]}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing line: {element}. Error: {e}\")\n",
        "\n",
        "# Define the pipeline\n",
        "with beam.Pipeline() as pipeline:\n",
        "    # Read lines and extract the state with a count of 1 for each record\n",
        "    state_counts = (\n",
        "        pipeline\n",
        "        | 'Read lines' >> beam.io.ReadFromText('/content/users_v.csv', skip_header_lines=1)  # Skip header\n",
        "        | 'Extract state' >> beam.ParDo(ExtractState())  # Extract state and emit (state, 1)\n",
        "        | 'Group by state' >> beam.CombinePerKey(sum)  # Sum the counts for each state\n",
        "    )\n",
        "\n",
        "    # Print the results\n",
        "    state_counts | 'Print state counts' >> beam.Map(lambda state_count: print(f\"{state_count[0]}: {state_count[1]} customers\"))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vaU45P3TOIW",
        "outputId": "479c7b8a-e448-4a43-e9fb-02f6344fa66f"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Missing pipeline option (runner). Executing pipeline using the default runner: DirectRunner.\n",
            "INFO:apache_beam.runners.worker.statecache:Creating state cache with size 104857600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VA: 44 customers\n",
            "UT: 50 customers\n",
            "SC: 50 customers\n",
            "ME: 43 customers\n",
            "WI: 56 customers\n",
            "MI: 56 customers\n",
            "SD: 48 customers\n",
            "AK: 52 customers\n",
            "NJ: 58 customers\n",
            "VT: 54 customers\n",
            "NY: 45 customers\n",
            "AZ: 50 customers\n",
            "KY: 43 customers\n",
            "MT: 49 customers\n",
            "CT: 63 customers\n",
            "ID: 51 customers\n",
            "GA: 53 customers\n",
            "OR: 39 customers\n",
            "AR: 53 customers\n",
            "DC: 50 customers\n",
            "NC: 54 customers\n",
            "MA: 45 customers\n",
            "OH: 28 customers\n",
            "ND: 46 customers\n",
            "NM: 42 customers\n",
            "HI: 51 customers\n",
            "CA: 49 customers\n",
            "CO: 48 customers\n",
            "NH: 39 customers\n",
            "DE: 48 customers\n",
            "WY: 50 customers\n",
            "WA: 42 customers\n",
            "OK: 47 customers\n",
            "IN: 45 customers\n",
            "AL: 55 customers\n",
            "NV: 40 customers\n",
            "KS: 49 customers\n",
            "WV: 40 customers\n",
            "TX: 48 customers\n",
            "RI: 35 customers\n",
            "IL: 40 customers\n",
            "MO: 42 customers\n",
            "MN: 41 customers\n",
            "FL: 43 customers\n",
            "NE: 43 customers\n",
            "MS: 36 customers\n",
            "TN: 44 customers\n",
            "MD: 41 customers\n",
            "IA: 53 customers\n",
            "PA: 35 customers\n",
            "LA: 31 customers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mGXCtBP9VQrm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
